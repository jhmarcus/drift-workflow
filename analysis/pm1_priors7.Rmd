---
title: "Revisiting prior families for trees: Part VII"
author: "Jason Willwerscheid"
date: "7/22/2020"
output:
  workflowr::wflow_html:
    code_folding: hide
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, comment = "#>",
                      fig.width = 5, fig.height = 4)
```

```{r load.pkgs}
suppressMessages({
  library(flashier)
  library(drift.alpha)
  library(tidyverse)
})
```

The purpose of this analysis is to experiment with the family of "three-pointmass priors" with mass on $-a$, $0$, and $b$. 

I use the balanced tree from the [previous analysis](pm1_priors6.html).

```{r sim}
set.seed(666)

p <- 10000
resid_sd <- 0.1

# Define tree by mean branch length at each depth:
branch_means <- rep(1, 4)
branch_sds <- rep(0, 4)
depth <- length(branch_means)
npop_pure <- 2^(depth - 1)

# Define admixtures by admixture proportions:
admix_pops <- matrix(nrow = 0, ncol = 0)
npop_admix <- ncol(admix_pops)

npop <- npop_pure + npop_admix

n <- sample(30:100, npop, replace = TRUE)
# n <- rep(50, npop)
K <- 2^depth - 1

FF <- matrix(nrow = p, ncol = K)
k <- 1
for (d in 1:depth) {
  for (i in 1:(2^(d - 1))) {
    FF[, k] <- rnorm(p, sd = branch_means[d] + rnorm(1, sd = branch_sds[d]))
    k <- k + 1
  }
}

tree_mat <- matrix(0, nrow = npop_pure, ncol = K)
k <- 1
for (d in 1:depth) {
  size <- 2^(depth - d)
  for (i in 1:(2^(d - 1))) {
    tree_mat[((i - 1) * size + 1):(i * size), k] <- 1
    k <- k + 1
  }
}

pop_means <- FF %*% t(tree_mat)
if (npop_admix > 0) {
  pop_means <- cbind(pop_means, pop_means %*% admix_pops)
}

Y <- NULL
for (i in 1:npop) {
  Y <- rbind(Y, matrix(pop_means[, i], nrow = n[i], ncol = p, byrow = TRUE))
}
Y <- Y + rnorm(sum(n) * p, sd = resid_sd)

plot_dr <- function(dr) {
  sd <- sqrt(dr$prior_s2)
  L <- dr$EL
  LDsqrt <- L %*% diag(sd)
  K <- ncol(LDsqrt)
  plot_loadings(LDsqrt[,1:K], rep(letters[1:npop], n)) +
    scale_color_brewer(palette="Set3")
}

threepm.fn = function(x, s, g_init, fix_g, output, ...) {
  if (is.null(g_init)) {
    nllik_given_ab <- function(par) {
      g_init <- ashr::unimix(rep(1/3, 3), a = c(-par[1], 0, par[2]), b = c(-par[1], 0, par[2]))
      ebnm_res <- ebnm::ebnm_ash(x, s, g_init = g_init)
      return(-ebnm_res$log_likelihood)
    }
    opt_res <- optim(
      par = c(1, 1), 
      fn = nllik_given_ab, 
      method = "L-BFGS-B", 
      lower = c(0, 0), 
      upper = c(Inf, Inf)
    )
    par <- opt_res$par
    g_init <- ashr::unimix(rep(1/3, 3), a = c(-par[1], 0, par[2]), b = c(-par[1], 0, par[2]))
  }
  
  return(flashier:::ebnm.nowarn(x = x,
                                s = s,
                                g_init = g_init,
                                fix_g = fix_g,
                                output = output,
                                prior_family = "ash",
                                prior = c(1, 1, 1),
                                ...))
}

prior.threepm = function(...) {
  return(as.prior(sign = 0, ebnm.fn = function(x, s, g_init, fix_g, output) {
    threepm.fn(x, s, g_init, fix_g, output, ...)
  }))
}

flexpm.fn = function(x, s, g_init, fix_g, output, ...) {
  if (is.null(g_init)) {
    nllik_given_ab <- function(par) {
      g_init <- ashr::unimix(rep(1/4, 4), a = c(-par[1], 0, par[2], -par[1]), b = c(-par[1], 0, par[2], par[2]))
      ebnm_res <- ebnm::ebnm_ash(x, s, g_init = g_init)
      return(-ebnm_res$log_likelihood)
    }
    opt_res <- optim(
      par = c(1, 1), 
      fn = nllik_given_ab, 
      method = "L-BFGS-B", 
      lower = c(0, 0), 
      upper = c(Inf, Inf)
    )
    par <- opt_res$par
    g_init <- ashr::unimix(rep(1/4, 4), a = c(-par[1], 0, par[2], -par[1]), b = c(-par[1], 0, par[2], par[2]))
  }
  
  return(flashier:::ebnm.nowarn(x = x,
                                s = s,
                                g_init = g_init,
                                fix_g = fix_g,
                                output = output,
                                prior_family = "ash",
                                prior = c(1, 1, 1, 1),
                                ...))
}

prior.flexpm = function(...) {
  return(as.prior(sign = 0, ebnm.fn = function(x, s, g_init, fix_g, output) {
    threepm.fn(x, s, g_init, fix_g, output, ...)
  }))
}

init.mean.factor <- function(resids, zero.idx) {
  u <- matrix(1, nrow = nrow(resids), ncol = 1)
  u[zero.idx, 1] <- 0
  v <- t(solve(crossprod(u), crossprod(u, resids)))
  return(list(u, v))
}

init.split.factor <- function(resids, zero.idx) {
  svd.res <- svd(resids, nu = 1, nv = 1)
  u <- svd.res$u
  u[zero.idx] <- 0
  u <- matrix(sign(u), ncol = 1)
  v <- t(solve(crossprod(u), crossprod(u, resids)))
  return(list(u, v))
}
```

With no admixtures, `flash` finds the tree:

```{r fl}
fl <- flash.init(Y) %>%
  flash.set.verbose(0) %>%
  flash.init.factors(EF = init.mean.factor(Y, NULL), 
                     prior.family = c(prior.threepm(), prior.normal())) %>%
  flash.fix.loadings(kset = 1, mode = 1L) %>%
  flash.backfit() %>%
  flash.add.greedy(Kmax = npop_pure - 1, 
                   prior.family = c(prior.threepm(), prior.normal()))

plot_dr(init_from_flash(fl))
```

If, however, I add in some admixed populations, the splits are all jumbled:

```{r sim2}
set.seed(666)

p <- 10000
resid_sd <- 0.1

# Define tree by mean branch length at each depth:
branch_means <- rep(1, 4)
branch_sds <- rep(0, 4)
depth <- length(branch_means)
npop_pure <- 2^(depth - 1)

# Define admixtures by admixture proportions:
admix_pops <- cbind(c(0, 0, 0, 0.4, 0.6, 0, 0, 0),
                   c(0, 0.15, 0.35, 0.5, 0, 0, 0, 0))
npop_admix <- ncol(admix_pops)

npop <- npop_pure + npop_admix

n <- sample(30:100, npop, replace = TRUE)
# n <- rep(50, npop)
K <- 2^depth - 1

FF <- matrix(nrow = p, ncol = K)
k <- 1
for (d in 1:depth) {
  for (i in 1:(2^(d - 1))) {
    FF[, k] <- rnorm(p, sd = branch_means[d] + rnorm(1, sd = branch_sds[d]))
    k <- k + 1
  }
}

tree_mat <- matrix(0, nrow = npop_pure, ncol = K)
k <- 1
for (d in 1:depth) {
  size <- 2^(depth - d)
  for (i in 1:(2^(d - 1))) {
    tree_mat[((i - 1) * size + 1):(i * size), k] <- 1
    k <- k + 1
  }
}

pop_means <- FF %*% t(tree_mat)
if (npop_admix > 0) {
  pop_means <- cbind(pop_means, pop_means %*% admix_pops)
}

Y <- NULL
for (i in 1:npop) {
  Y <- rbind(Y, matrix(pop_means[, i], nrow = n[i], ncol = p, byrow = TRUE))
}
Y <- Y + rnorm(sum(n) * p, sd = resid_sd)

fl <- flash.init(Y) %>%
  flash.set.verbose(0) %>%
  flash.init.factors(EF = init.mean.factor(Y, NULL), 
                     prior.family = c(prior.threepm(), prior.normal())) %>%
  flash.fix.loadings(kset = 1, mode = 1L) %>%
  flash.backfit() %>%
  flash.add.greedy(Kmax = npop_pure - 1, 
                   prior.family = c(prior.threepm(), prior.normal()))

plot_dr(init_from_flash(fl))
```

It's likely that I simply got lucky in the previous analysis and unlucky here. We'll need a better way to encourage sparsity in the later splits.

## Sparse PCA

First I look at how sparse PCA does (using package `sparsepca`). It mostly just clusters populations -- there's no evidence of a tree-like structure here.

```{r spca}
library(sparsepca)
spca.t <- system.time(spca.res <- spca(t(Y), k = 8, max_iter = 10000, verbose = FALSE))
plot_dr(init_from_EL(Y, spca.res$loadings))
```

## Flash with point-normal priors

Next I try `flash` with a more sparsity-inducing family of priors. I only fit up to the third factor since that's where the problems begin.

```{r dirichlet}
fl2 <- flash.init(Y) %>%
  flash.set.verbose(0) %>%
  flash.init.factors(EF = init.mean.factor(Y, NULL), 
                     prior.family = c(prior.threepm(), prior.normal())) %>%
  flash.fix.loadings(kset = 1, mode = 1L) %>%
  flash.backfit() %>%
  flash.add.greedy(Kmax = 1, prior.family = c(prior.threepm(), prior.normal())) 

fl.pn <- fl2 %>%
  flash.add.greedy(Kmax = 1, prior.family = c(prior.point.normal(), prior.normal()))

plot_dr(init_from_flash(fl.pn))
```

The point-normal prior basically just returns the SVD solution with no additional sparsity. Indeed, the first principal component after residualizing out the first two factors appears as follows:

```{r svd}
svd.res <- svd(Y - fitted(fl2), nu = 2, nv = 2)
plot(svd.res$u[, 1])
```

## Varimax rotation

The problem is that since I'm using a balanced tree, the next two eigenvalues are pretty similar, so it's very easy to get the corresponding splits mixed up.

```{r svd2}
cat("Next 8 eigevalues:", round(svd.res$d[1:8]))
```

One solution would be to do a varimax rotation to induce sparsity. After doing so, the third factor appears as follows: 

```{r varimax}
varimax.res <- varimax(svd.res$u, normalize = FALSE)
plot(varimax.res$loadings[, 1])
```

Using this factor to initialize `flash` (with a three-pointmass prior) then gives me the split I want:

```{r varimax2}
EL <- varimax.res$loadings[, 1, drop = FALSE]
EF <- (svd.res$v %*% t(solve(varimax.res$rotmat)))[, 1, drop = FALSE]
fl.varimax <- fl2 %>%
  flash.init.factors(EF = list(EL, EF),
                     prior.family = c(prior.threepm(), prior.normal())) %>%
  flash.backfit(kset = 3)
plot_dr(init_from_flash(fl.varimax))
```

Note that I cheated by using exactly two principal components. If I didn't know anything about the tree, it might make sense to look at all principal components with eigenvalues that are reasonably similar to the first. If, for example, I take all PCs with eigenvalues that are least half as large as the first PC, I'd need to rotate five PCs. I use this criterion to add new factors up to a total of eight:

```{r varimax4}
add_split <- function(fl, eigen.thresh = 0.5) {
  svd.res <- svd(Y - fitted(fl), nu = 10, nv = 10)
  n.eigen <- sum(svd.res$d > eigen.thresh * svd.res$d[1])
  if (n.eigen > 1) {
    varimax.res <- varimax(svd.res$u[, 1:n.eigen], normalize = FALSE)
    EL <- varimax.res$loadings[, 1, drop = FALSE]
    EF <- (svd.res$v[, 1:n.eigen] %*% t(solve(varimax.res$rotmat)))[, 1, drop = FALSE]
  } else {
    EL <- svd.res$u[, 1, drop = FALSE]
    EF <- svd.res$v[, 1, drop = FALSE]
  }
  fl.new <- fl %>%
    flash.init.factors(EF = list(EL, EF),
                       prior.family = c(prior.threepm(), prior.normal())) %>%
    flash.backfit(kset = fl$n.factors + 1)
  return(fl.new)
}

fl3 <- fl2
for (i in 1:6) {
  fl3 <- add_split(fl3)
}
plot_dr(init_from_flash(fl3))
```

Finally, I relax the priors for both the first three-pointmass fit and this pre-rotated fit and compare ELBOs:

```{r elbo}
fl.relax <- fl
for (k in 2:fl.relax$n.factors) {
  fl.relax$flash.fit$g[[k]][[1]]$pi <- rep(0.25, 4)
  fl.relax$flash.fit$g[[k]][[1]]$a <- c(fl.relax$flash.fit$g[[k]][[1]]$a,
                                        0.9 * min(fl.relax$flash.fit$g[[k]][[1]]$a))
  fl.relax$flash.fit$g[[k]][[1]]$b <- c(fl.relax$flash.fit$g[[k]][[1]]$b,
                                        0.9 * max(fl.relax$flash.fit$g[[k]][[1]]$b))
  fl.relax$flash.fit$ebnm.fn[[k]][[1]] <- prior.unimodal()[[1]]$ebnm.fn
}
fl.relax <- fl.relax %>% 
  flash.backfit()
cat("ELBO (no pre-rotations):", fl.relax$elbo)
plot_dr(init_from_flash(fl.relax))

fl3.relax <- fl3
for (k in 2:fl3.relax$n.factors) {
  fl3.relax$flash.fit$g[[k]][[1]]$pi <- rep(0.25, 4)
  fl3.relax$flash.fit$g[[k]][[1]]$a <- c(fl3.relax$flash.fit$g[[k]][[1]]$a,
                                         0.9 * min(fl3.relax$flash.fit$g[[k]][[1]]$a))
  fl3.relax$flash.fit$g[[k]][[1]]$b <- c(fl3.relax$flash.fit$g[[k]][[1]]$b,
                                         0.9 * max(fl3.relax$flash.fit$g[[k]][[1]]$b))
  fl3.relax$flash.fit$ebnm.fn[[k]][[1]] <- prior.unimodal()[[1]]$ebnm.fn
}
fl3.relax <- fl3.relax %>% 
  flash.backfit()
cat("ELBO (with pre-rotations):", fl3.relax$elbo)
plot_dr(init_from_flash(fl3.relax))
```
