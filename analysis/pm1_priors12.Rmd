---
title: "Revisiting prior families for trees: Part XII"
author: "Jason Willwerscheid"
date: "7/22/2020"
output:
  workflowr::wflow_html:
    code_folding: hide
    toc: false
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, comment = "#>",
                      fig.width = 5, fig.height = 4)
```

```{r load.pkgs}
suppressMessages({
  library(flashier)
  library(drift.alpha)
  library(tidyverse)
})
```

Note that simply running greedy flash on the covariance matrix for the balanced tree with four populations of equal sizes gives us the solution we want. 

```{r sim}
sim_tree <- function(n_range, 
                     p = 10000, 
                     branch_means, 
                     branch_sds, 
                     resid_sd = 0.1,
                     admix_pops = NULL, 
                     outgroup = FALSE, 
                     seed = 666) {
  set.seed(seed)
  
  depth <- length(branch_means)
  npop_pure <- 2^(depth - 1)

  if (is.null(admix_pops)) {
    admix_pops <- matrix(nrow = 0, ncol = 0)
  }
  npop_admix <- ncol(admix_pops)
  
  npop <- npop_pure + npop_admix + outgroup
  
  if (length(n_range) == 1) {
    n <- rep(n_range, npop)
  } else {
    n <- sample(30:100, npop, replace = TRUE)
  }
  K <- 2^depth - 1
  
  FF <- matrix(nrow = p, ncol = K)
  k <- 1
  for (d in 1:depth) {
    for (i in 1:(2^(d - 1))) {
      FF[, k] <- rnorm(p, sd = branch_means[d] + rnorm(1, sd = branch_sds[d]))
      k <- k + 1
    }
  }
  
  tree_mat <- matrix(0, nrow = npop_pure, ncol = K)
  k <- 1
  for (d in 1:depth) {
    size <- 2^(depth - d)
    for (i in 1:(2^(d - 1))) {
      tree_mat[((i - 1) * size + 1):(i * size), k] <- 1
      k <- k + 1
    }
  }
  
  pop_means <- FF %*% t(tree_mat)
  if (npop_admix > 0) {
    pop_means <- cbind(pop_means, pop_means %*% admix_pops)
  }
  if (outgroup) {
    pop_means <- cbind(pop_means, rnorm(p, mean = 0, sd = sqrt(sum(branch_sds^2))))
  }
  
  Y <- NULL
  for (i in 1:npop) {
    Y <- rbind(Y, matrix(pop_means[, i], nrow = n[i], ncol = p, byrow = TRUE))
  }
  Y <- Y + rnorm(sum(n) * p, sd = resid_sd)
  
  plot_fl <- function(fl, mode = 1) {
    LDsqrt <- fl$loadings.pm[[mode]] %*% diag(sqrt(fl$loadings.scale))
    K <- ncol(LDsqrt)
    plot_loadings(LDsqrt[,1:K], rep(letters[1:npop], n)) +
      scale_color_brewer(palette="Set3")
  }
  
  return(list(Y = Y, plot_fn = plot_fl))
}
  
init.mean.factor <- function(resids, zero.idx) {
  u <- matrix(1, nrow = nrow(resids), ncol = 1)
  u[zero.idx, 1] <- 0
  v <- t(solve(crossprod(u), crossprod(u, resids)))
  return(list(u, v))
}

balanced_4pop <- sim_tree(n_range = 50,
                          p = 10000,
                          branch_means = rep(1, 3),
                          branch_sds = rep(0, 3),
                          resid_sd = 0.1)
covmat <- cov(t(balanced_4pop$Y))
```

I use point-Laplace priors with no backfit here:

```{r pl}
fl_g <- flash.init(covmat) %>%
  flash.set.verbose(0) %>%
  flash.add.greedy(Kmax = 4, 
                   prior.family = prior.point.laplace())

balanced_4pop$plot_fn(fl_g)
```

Point-normal priors also work fine:

```{r pn}
fl_g2 <- flash.init(covmat) %>%
  flash.set.verbose(0) %>%
  flash.add.greedy(Kmax = 4, 
                   prior.family = prior.point.normal())

balanced_4pop$plot_fn(fl_g2)
```

Assuming that the fit "discovers" the constraint $L = F$ (and it seems to do so fairly easily), the model here is
$$ \text{Cov}(Y) \sim LL' + E $$
where $E$ has the "constant" variance structure
$$ E_{ij} \sim N(0, \sigma^2) $$

A better model, however, would fit
$$ \text{Cov}(Y) \sim LL' + \sigma_r^2 I + E $$
since the expected covariance matrix for $Y = LF' + E$ when $F_j \sim N(0, I_p)$ and $E_{ij} \sim N(0, \sigma_r^2)$ is $LL' + \sigma_r^2I$. If we put a prior on $\sigma_r^2 \sim N(0, \sigma_d^2)$, then the model becomes  
$$ \text{Cov}(Y) \sim LL' + \tilde{E} $$
where
$$ \tilde{E}_{ij} \sim N(0, \sigma^2 + \delta_{ij} \sigma_d^2) $$
(Note that the MLE for $\sigma_d^2$ is $\sigma_r^4$, not $\sigma_r^2$.)
I fit this last model by iterating between 1) estimating $\sigma_d^2$ and 2) treating $\sigma_d^2$ as fixed and fitting the flash model using a "noisy" variance structure. I initialize $\sigma_d^2$ at zero. 

```{r diag}
fl <- flash.init(covmat) %>%
  flash.set.verbose(0) %>%
  flash.add.greedy(Kmax = 4, 
                   prior.family = prior.point.laplace())

n <- nrow(covmat)
diag_S2 <- 0
elbo_diff <- Inf
while (elbo_diff > 0.01) {
  old_elbo <- fl$elbo
  fl <- flash.init(covmat, S = diag(rep(sqrt(diag_S2), n)), var.type = 0) %>%
    flash.set.verbose(0) %>%
    flash.init.factors(EF = fl$flash.fit$EF, EF2 = fl$flash.fit$EF2,
                       prior.family = prior.point.laplace()) %>%
    flash.backfit()
  cat("SD (diagonal):", formatC(sqrt(diag_S2), format = "e", digits = 2),
      " SD (non-diag):", formatC(sqrt(1 / fl$flash.fit$tau[1, 2]), format = "e", digits = 2),
      " ELBO:", fl$elbo, "\n")
  elbo_diff <- fl$elbo - old_elbo
  
  diag_S2 <- mean(diag(covmat)^2 
                  - 2 * diag(covmat) * rowSums(fl$flash.fit$EF[[1]] * fl$flash.fit$EF[[2]])
                  + rowSums(fl$flash.fit$EF2[[1]] * fl$flash.fit$EF2[[2]])
                  - rowSums(fl$flash.fit$EF[[1]]^2 * fl$flash.fit$EF[[2]]^2))
  diag_S2 <- diag_S2 + sum(crossprod(fl$flash.fit$EF[[1]] * fl$flash.fit$EF[[2]])) / n
  diag_S2 <- diag_S2 - 1 / fl$flash.fit$tau[1, 2]
}

balanced_4pop$plot_fn(fl)
```

However, it seems that, as in the [previous analysis](pm1_priors11.html), some overfitting problems are beginning to rear their heads --- adding the diagonal variance term allows the non-diagonal variance to become very small, and as a result few loadings are estimated to be zero. Compare LFSRs for the first fit and this last one:

```{r lfsr}
cat("Nonzero loadings per factor (no diagonal variance term):", 
    colSums(fl_g$loadings.lfsr[[1]] < 0.05))
cat("Nonzero loadings per factor (with diagonal variance):", 
    colSums(fl$loadings.lfsr[[1]] < 0.05))
```

